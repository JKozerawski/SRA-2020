{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Lab_2_instructions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJXrsPstyAEA",
        "colab_type": "text"
      },
      "source": [
        "# Lab 2\n",
        "Neural Networks for MNIST dataset\n",
        "\n",
        "## Useful links:\n",
        "\n",
        "Information on Pytorch layers: [link](https://pytorch.org/docs/stable/nn.html)\n",
        "\n",
        "And more specifically:\n",
        "\n",
        "\n",
        "*   Linear layers: [link](https://pytorch.org/docs/stable/nn.html#linear-layers)\n",
        "*   Loss layers: [link](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "*   Activation functions: [link](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
        "*   Datasets and dataloaders: [link](https://pytorch.org/docs/stable/data.html)\n",
        "*   Saving and loading models: [link](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
        "\n",
        "TSNE visualization: [link](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfcMenIEmic1",
        "colab_type": "text"
      },
      "source": [
        "#Information about network training:\n",
        "\n",
        "### How to use loss function:\n",
        "```\n",
        "# define the loss function once (before training):\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# to calculate our loss after the forward pass:\n",
        "current_loss = loss_function(outputs, target)\n",
        "\n",
        "# perform backward pass:\n",
        "current_loss.backward()\n",
        "```\n",
        "\n",
        "### Network optimization (learning):\n",
        "```\n",
        "# define the optimizer once (before training):\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # optimizing parameters (weights) with learning rate 0.01\n",
        "\n",
        "# before performing the backward pass clear the information about the gradients from the previous pass:\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# after performing the backward pass\n",
        "optimizer.step()\n",
        "```\n",
        "\n",
        "### Forward pass:\n",
        "```\n",
        "#if you have already defined a model, the only thing you have to do is:\n",
        "outputs = model(inputs)\n",
        "```\n",
        "\n",
        "#Information about defining the network:\n",
        "\n",
        "Every model will have similar structure:\n",
        "```\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define your layers here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass operations here\n",
        "        return x\n",
        "```\n",
        "\n",
        "There are two distinc functions here, the ```__init__``` and ```forward```.\n",
        "\n",
        "In the ```__init__``` function we will define layers that we will later on use in our forward pass.\n",
        "\n",
        "In the ```forward``` function we will define step by step what should happen in our forward pass.\n",
        "\n",
        "# Layers\n",
        "### Linear\n",
        "First layer we can use is a linear (or fully connected) layer. We can define it as:\n",
        "```\n",
        "# Linear layer with 5 inputs and 2 outputs (goes inside the __init__)\n",
        "self.fc = torch.nn.Linear(in_features=5, out_features=2)\n",
        "\n",
        "# moving data through the layer (goes into the forward function)\n",
        "output = self.fc(input) \n",
        "```\n",
        "### Activation\n",
        "Activation functions don't have to be defined in the ```__init__``` function as long as they don't have any trainable parameters (and most of them don't have any).\n",
        "```\n",
        "# moving data through the layer with sigmoid (goes into the forward function)\n",
        "output = F.sigmoid(self.fc(input)) \n",
        "\n",
        "# moving data through the layer with relu (goes into the forward function)\n",
        "output = F.relu(self.fc(input)) \n",
        "```\n",
        "\n",
        "### Reshape\n",
        "Frequently you will have to reshape your input (from 2D to 1D for example).\n",
        "```\n",
        "# if input is of shape (N, 10, 10)\n",
        "output = input.view(-1, 100)\n",
        "# now output is of shape (N, 100)\n",
        "```\n",
        "\n",
        "### 2D Convolution\n",
        "Definition of the convolution layer\n",
        "```\n",
        "# Convolution layer with 10 filters of size 3x3. The input has 5 channels.\n",
        "self.conv = nn.Conv2d(5, 10, kernel_size=3)\n",
        "\n",
        "# Forward pass:\n",
        "output = self.conv(input)\n",
        "```\n",
        "\n",
        "### 2D max pooling\n",
        "```\n",
        "# Performing a 2D max pooling operation with a kernel of size 2x2\n",
        "output = F.max_pool2d(self.conv(input), 2)\n",
        "```\n",
        "\n",
        "### Dropout\n",
        "```\n",
        "# 1D dropout performed on the output of a linear layer\n",
        "output = F.dropout(self.linear(input))\n",
        "```\n",
        "\n",
        "# Data transformations\n",
        "```\n",
        "# simplest transformation (transforming image to PyTorch tensor):\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# you can add more transformations (after you converted image to tensor). Simplest would be normalization (for 1 channel data (grayscale)):\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,), (std,))])\n",
        "```\n",
        "\n",
        "# Saving and loading models\n",
        "Keeping progress of our training is very important. Being able to save and load our previous models will become very helpful.\n",
        "\n",
        "Working on entire model:\n",
        "```\n",
        "PATH = \"./mnist_model.pt\"\n",
        "# saving entire model:\n",
        "torch.save(model, PATH)\n",
        "# loading entire model:\n",
        "model = torch.load(PATH)\n",
        "```\n",
        "\n",
        "Saving more details. Useful when stopping and resuming training.\n",
        "```\n",
        "PATH = \"./mnist_model.pt\"\n",
        "# saving more detailed information:\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            ...\n",
        "            }, PATH)\n",
        "# loading more detailed information:\n",
        "model = Net() # initialize the object first\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # initialize the object first\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO9O9XuTgwkg",
        "colab_type": "text"
      },
      "source": [
        "# INSTRUCTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SXmvX5uXajB",
        "colab_type": "text"
      },
      "source": [
        "Mount your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0S4wevQXY0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6_w7cFj-TGm",
        "colab_type": "text"
      },
      "source": [
        "Create a folder in your Google Drive named \"data\".\n",
        "\n",
        "You can do it either manually or as command line:\n",
        "```\n",
        "%cd /content/gdrive/My\\ Drive/\n",
        "%mkdir data\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEsOmGaI9Fpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# general path:\n",
        "data_path = \"/content/gdrive/My\\ Drive/data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV4K7gCDXsLs",
        "colab_type": "text"
      },
      "source": [
        "Move to that folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOC25sFyXulw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# go to the folder:\n",
        "%cd /content/gdrive/My\\ Drive/data/\n",
        "# print out the content of the folder:\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7hWirg1yAEB",
        "colab_type": "text"
      },
      "source": [
        "Imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqIfVxocyAED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd5stBPKYDXE",
        "colab_type": "text"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYh5DfWX_DdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## Read MNIST ########\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0 # means to use all\n",
        "# how many samples per batch to load\n",
        "batch_size = 64\n",
        "# where the dataset is:\n",
        "dataset_path = \"./MNIST\"\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# create training and test datasets\n",
        "train_data = datasets.MNIST(root=dataset_path, train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root=dataset_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HJuZLroIY5FE"
      },
      "source": [
        "Visualize the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jLYZgyHCY5FH",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "    \n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy()\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    # print out the correct label for each image\n",
        "    # .item() gets the value contained in a Tensor\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TighTVKsyAEJ",
        "colab_type": "text"
      },
      "source": [
        "Define the network:\n",
        "\n",
        "Have only a single linear layer (fully connected one). No activation functions.\n",
        "\n",
        "Remember to reshape the input in your forwards pass (from Nx28x28 to Nx784) before feeding it to the linear layer.\n",
        "N is the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd547-kayAEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define your layers here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass operations here\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp4RP1oByAEY",
        "colab_type": "text"
      },
      "source": [
        "Initialize the network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bFdy8qpyAEY",
        "colab_type": "code",
        "colab": {},
        "outputId": "d09f224a-6af7-44df-ce33-48fabf57d076"
      },
      "source": [
        "model = Net()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll6xMiEQyAEd",
        "colab_type": "text"
      },
      "source": [
        "Specify loss and optimization functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVacnSsgyAEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify loss function\n",
        "criterion = None # modify that\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = None # modify that"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBpytd08yAEh",
        "colab_type": "text"
      },
      "source": [
        "Training the network.\n",
        "\n",
        "We will iterate through our dataset. For evey iteration we need to:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhWP7P7CyAEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 10\n",
        "\n",
        "model.train() # prep model for training\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    for data, target in train_dataloader:\n",
        "        \n",
        "        # clear the gradients of all optimized variables\n",
        "        \n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        \n",
        "        # calculate the loss\n",
        "        loss = 0 # change this\n",
        "        \n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        \n",
        "        # perform a single optimization step (parameter update)\n",
        "\n",
        "        # if you have a learning rate scheduler - perform a its step in here\n",
        "        \n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    # print training statistics \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_dataloader.dataset)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY8K07wLyAEm",
        "colab_type": "text"
      },
      "source": [
        "Test the network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrv9Roz-yAEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()  # prep model for testing\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_dataloader:\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test set: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeLJtM1Z1Z-D",
        "colab_type": "text"
      },
      "source": [
        "Now modify the code above to perform the test pass after every training epoch.\n",
        "\n",
        "In two separate arrays keep track of the training loss and the testing accuracy after every epoch.\n",
        "\n",
        "Plot them using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5j9PzoI1sHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting:\n",
        "x_range = np.arange(1, n_epochs+1)\n",
        "fig, axs = plt.subplots(2)\n",
        "axs[0].plot(x_range, train_loss_progress, c='b', label=\"Train loss\")\n",
        "axs[1].plot(x_range, test_accuracy_progress, c='r', label=\"Test accuracy\")\n",
        "axs[0].legend()\n",
        "axs[1].legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQjQwDEipp_o",
        "colab_type": "text"
      },
      "source": [
        "# Further tasks:\n",
        "Perform following modifications (one at a time):\n",
        "\n",
        "1.   Change the model to be used on GPU. Compare the runtime.\n",
        "2.   Modify the network to have 3 linear layers. Choose their dimensions.\n",
        "3.   Compare using sigmoid vs relu activation functions. The last layer does not require activation function.\n",
        "4.   Check the impact of the batch size. Use batch sizes 4, 16, and 128.\n",
        "5.   For 3 layer network with relu activations:\n",
        "    *   Train for 25 and 50 epochs.\n",
        "    *   For 25 epoch training - add a learning rate scheduler to your training procedure. Compare the impact it has on the performance. Use a step scheduler that will decrease the learning rate by 10 after every 10 epochs.\n",
        "    *   On top of that add momentum=0.9 to the optimizer\n",
        "\n",
        "In your research report - provide results and analysis of the conducted experiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcXnBT4zmLIU",
        "colab_type": "text"
      },
      "source": [
        "#Using a CNN:\n",
        "Substitute your current network with a Convolutional Neural Network with following layers:\n",
        "\n",
        "*   2D convolution with 10 kernels of size 5\n",
        "*   2D convolution with 20 kernels of size 5\n",
        "*   fully connected (linear) layer with output size 50\n",
        "*   final fully connected layer with output size 10\n",
        "\n",
        "Modify the transforms for the dataset to include a normalization of data. Numbers for MNIST are: mean is 0.1307, std is 0.3081.\n",
        "\n",
        "Perform following modifications (one at a time) to the forward pass:\n",
        "1.   Use relu activation functions for both conv layers and for the first linear layer\n",
        "2.   Add a dropout layer between the two linear layers\n",
        "3.   Add 2D max pooling layer before performing a relu activation on both conv layers\n",
        "\n",
        "Note the differences in performances when modifying the network.\n",
        "\n",
        "In your research report - provide results and analysis of the conducted experiments.\n",
        "\n"
      ]
    }
  ]
}